{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/9-coding/PyTorch/blob/main/22-save_load_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save and Load Model\n",
        "PyTorch는 python의 pickle을 활용하여 직렬화(Serialize)하여 객체를 저장하고 역직렬화(Deserialize)를 통해 볼러올 수 있음."
      ],
      "metadata": {
        "id": "G1T65rU1JWxJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import init\n",
        "from collections import OrderedDict"
      ],
      "metadata": {
        "id": "zDomW-5Qu91a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `torch.save` & `torch.load`\n",
        "- 모델의 정보를 경로에 저장하고 불러옴.\n",
        "- 모델 전체를 저장하거나 상태만 저장할 때 모두 사용됨.\n",
        "- `map_location`을 활용하면 device에 상관없이 불러올 수 있음."
      ],
      "metadata": {
        "id": "wdSSvBFkfNws"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 비교\n",
        "### Save\n",
        "- 전체: `torch.save(model, 'model.pt')`\n",
        "- 상태: `torch.save(model.state_dict(), model_params.pt')`\n",
        "\n",
        "### load\n",
        "- 전체: `torch.load('model.pt')`\n",
        "- 상태: `model.load_state_dict(torch.load('model_params.pt'))`"
      ],
      "metadata": {
        "id": "MZSKk64Hg53X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self, n_in_f, n_out_f, w, b):\n",
        "    super().__init__()\n",
        "    init_weigths = torch.ones( (n_in_f, n_out_f) )\n",
        "    init_bias = torch.zeros( (n_out_f,) )\n",
        "\n",
        "    self.l0 = nn.Linear(n_in_f, n_out_f)\n",
        "\n",
        "    init.constant_(self.l0.weight, w)\n",
        "    if self.l0.bias is not None:\n",
        "      init.constant_(self.l0.bias, b)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.l0(x)"
      ],
      "metadata": {
        "id": "1Tpv8WqDyb9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델의 Parameters 저장\n",
        "`state_dict`를 활용해 모델의 상태를 저장함.\n",
        "- Structure 등은 저장되지 않음.\n",
        "- PyTorch 버전에 관계없이 사용 가능.\n",
        "- 모델을 불러올 때 동일한 형태의 클래스가 선언되어 있어야 함."
      ],
      "metadata": {
        "id": "FqQj2A4boHD2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `state_dict()`\n",
        "- 객체의 상태를 가지고 있어 상태를 저장하고 복원할 수 있음.\n",
        "- 모델의 parameter 상태와 buffer의 상태 저장\n",
        "- 현재 Module instance의 상태에 해당하는 OrderedDict 객체 `state_dict` 반환.\n"
      ],
      "metadata": {
        "id": "a9nkpCwjoFLo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `load_state_dict(state_dict)`\n",
        "현재 Module 인스턴스의 상태를 argument로 넘겨진 OrderedDict 객체 state_dict를 이용해 설정\n",
        "\n",
        "- missing_keys : 로드하려는 state_dict에는 있으나 load_state_dict메서드를 호출한 Module 객체에는 없는 키들.\n",
        "- unexpected_keys : Module 객체에는 있으나 인자로 넘겨진 state_dict에는 없는 키들."
      ],
      "metadata": {
        "id": "kFevbUSJsiYs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `torch.save(state_dict,'file_path') & state_dict=torch.load('file_path')`\n",
        "\n",
        "`state_dict`객체는 torch의 `save` `load`를 이용해 파일로 저장되거나 로딩됨."
      ],
      "metadata": {
        "id": "JlklNPYPuUbS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 객체를 생성하고, 이에 대한 파라메터 확인후\n",
        "# 파라메터만 저장.\n",
        "model1 = Model(3, 1, 1., 0.5)\n",
        "print(list(model1.named_parameters()))\n",
        "torch.save(model1.state_dict(), 'model_params.pth')\n",
        "\n",
        "# 새로운 모델 객체를 생성.\n",
        "# 해당 모델 객체는 구조는 같으나, 파라메터들의 초기값은 다름.\n",
        "model2 = Model(3, 1, 2., 1.5)\n",
        "\n",
        "print('===============')\n",
        "for old, new in zip(model1.parameters(), model2.parameters()):\n",
        "\n",
        "  if not torch.equal(old,new):\n",
        "    print('model and n_model w/ default init do not have parameters with the same values!')\n",
        "    break\n",
        "else:\n",
        "  print('model and n_model w/ default init have parameters with the same values!')\n",
        "print('===============')\n",
        "\n",
        "# 이전 저장한 parameters에 대한 state_dict를\n",
        "# 로드하고 해당 state_dict로 새로만든 모델의\n",
        "# 파라메터를 설정하고 이전 모델과 비교.\n",
        "# load parameters and restore old parameters into new model\n",
        "loaded_params_ordered_dict = torch.load('model_params.pth')\n",
        "print(f'{type(loaded_params_ordered_dict)=}') # collections.OredredDict\n",
        "\n",
        "ret_v = model2.load_state_dict(loaded_params_ordered_dict)\n",
        "print(f'{type(ret_v)}: {ret_v}')\n",
        "\n",
        "print('===============')\n",
        "for old, new in zip(model1.parameters(), model2.parameters()):\n",
        "\n",
        "  if not torch.equal(old,new):\n",
        "    print('model and n_model do not have parameters with the same values!')\n",
        "    break\n",
        "else:\n",
        "  print('model and n_model have parameters with the same values!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ult44kEoL3tH",
        "outputId": "53d0805b-840d-4cfa-8c38-904b7e17d3d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('l0.weight', Parameter containing:\n",
            "tensor([[1., 1., 1.]], requires_grad=True)), ('l0.bias', Parameter containing:\n",
            "tensor([0.5000], requires_grad=True))]\n",
            "===============\n",
            "model and n_model w/ default init do not have parameters with the same values!\n",
            "===============\n",
            "type(loaded_params_ordered_dict)=<class 'collections.OrderedDict'>\n",
            "<class 'torch.nn.modules.module._IncompatibleKeys'>: <All keys matched successfully>\n",
            "===============\n",
            "model and n_model have parameters with the same values!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## model 전체 저장\n",
        "- Parameters와 Structure 함께 저장\n",
        "- pickle에 의존하여 인스턴스를 직렬화하므로 모델 클래스 정의가 필요함.\n",
        "- 버전이 크게 바뀔 경우 안 될 확률이 매우 높으므로 주기적으로 최신 버전으로 다시 저장 필요."
      ],
      "metadata": {
        "id": "HI3gpstTnPcU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 저장할 모델 생성.\n",
        "model = Model(3, 1, 2., 1.5)\n",
        "\n",
        "# 모델 저장\n",
        "torch.save(model, 'model.pth')\n",
        "\n",
        "# 저장된 model 로드.\n",
        "n_model = torch.load('model.pth')\n",
        "print(f'{type(n_model)=}, {n_model}')\n",
        "\n",
        "# 두 모델의 parameters비교.\n",
        "for old, new in zip(model.parameters(), n_model.parameters()):\n",
        "  if not torch.equal(old,new):\n",
        "    print('model and n_model do not have parameters with the same values!')\n",
        "    break\n",
        "else:\n",
        "  print('model and n_model have parameters with the same values!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jUY-nTIu7ty",
        "outputId": "c394444f-b7ed-4221-fe25-1022a405089a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "type(n_model)=<class '__main__.Model'>, Model(\n",
            "  (l0): Linear(in_features=3, out_features=1, bias=True)\n",
            ")\n",
            "model and n_model have parameters with the same values!\n"
          ]
        }
      ]
    }
  ]
}