{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM0TcfSW8zCPSGKXvuwTORB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/9-coding/PyTorch/blob/main/26-loss_functions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNkJ9xK0SZq4"
      },
      "source": [
        "# Loss Functions\n",
        "ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì´ dataì™€ ì–¼ë§ˆë‚˜ ì˜ ë§ëŠ”ì§€ ì¸¡ì •í•˜ëŠ” function.\n",
        "- loss ê°’ì€ functionì— ë”°ë¼ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŒ.\n",
        "- ì¸ê³µì§€ëŠ¥ í•™ìŠµì€ lossë¥¼ ìµœì†Œí™”í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ ì§„í–‰.\n",
        "\n",
        "Binary Classification\n",
        "- BCELoss or BCEWithLogitsLoss\n",
        "\n",
        "Multiple-class Classification:\n",
        "- CrossEntropyLoss\n",
        "- LogSoftmax + NLLLoss\n",
        "\n",
        "Multi-label Classification:\n",
        "- sigmoid + BCELoss\n",
        "- MultiLablelSoftMarginLoss"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "UL_2NAbcGEIT"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Binary classification"
      ],
      "metadata": {
        "id": "KuQ83D48JrCR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daYlkZr1SfMF"
      },
      "source": [
        "## BCELoss\n",
        "binary classificationì— ì‚¬ìš©.\n",
        "- modelì˜ ì¶œë ¥ì´ 0ê³¼ 1 ì‚¬ì´ ê°’ì´ì–´ì•¼ í•˜ê¸° ë•Œë¬¸ì— ì¶œë ¥ìœ¼ë¡œ sigmoid ì‚¬ìš©.\n",
        "- pred: sigmoid\n",
        "- label: 0ê³¼ 1 ì‚¬ì´ì˜ ì‹¤ì œ ë¼ë²¨ê°’"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "35ut6qv2Se40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a723619f-fa9c-4236-9d14-3c5d7ab93f13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BCELoss: 0.514159619808197\n"
          ]
        }
      ],
      "source": [
        "# ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’\n",
        "outputs = torch.tensor([0.7, 0.2, 0.9], requires_grad=True).float()\n",
        "targets = torch.tensor([1.0, 0.0, 1.0]).float()\n",
        "\n",
        "# BCELoss ì„ ì–¸\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# ì‹œê·¸ëª¨ì´ë“œ í™œì„±í™” ì ìš©\n",
        "outputs = torch.sigmoid(outputs)\n",
        "\n",
        "# ì†ì‹¤ ê³„ì‚°\n",
        "loss = criterion(outputs, targets)\n",
        "print('BCELoss:', loss.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0321B4TSpAS"
      },
      "source": [
        "## BCEWithLogitsLoss\n",
        "- BCELossì˜ variation.\n",
        "- ë‚´ë¶€ì ìœ¼ë¡œ sigmoidë¥¼ ê²°í•©ì‹œì¼°ìœ¼ë¯€ë¡œ ì…ë ¥ìœ¼ë¡œ logit scoreë¥¼ ë°›ì„ ìˆ˜ ìˆìŒ.\n",
        "- pred: sigmoidì˜ ì…ë ¥ê°’ì¸ **logit score**\n",
        "- label: 0ê³¼ 1 ì‚¬ì´ì˜ ì‹¤ì œ ë¼ë²¨ ê°’"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3ra2a870SZdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7936d8dc-f9bb-48f1-dc25-2e483022d2b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BCEWithLogitsLoss: 0.3048\n"
          ]
        }
      ],
      "source": [
        "# ì›ì‹œ ì¶œë ¥ê°’ (ì‹œê·¸ëª¨ì´ë“œ í™œì„±í™” ì ìš© ì „ raw score)\n",
        "raw_outputs = torch.tensor([0.5, -1.0, 2.0], requires_grad=True)\n",
        "targets = torch.tensor([1.0, 0.0, 1.0])\n",
        "\n",
        "# BCEWithLogitsLoss ì„ ì–¸\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# ì†ì‹¤ ê³„ì‚° (ì‹œê·¸ëª¨ì´ë“œ ë‚´ë¶€ ì ìš©)\n",
        "loss = criterion(raw_outputs, targets)\n",
        "print(f'BCEWithLogitsLoss: {loss.item():.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-class classification"
      ],
      "metadata": {
        "id": "5DVFVHylJ7jj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaI-waGVSsiF"
      },
      "source": [
        "## CrossEntropyLoss\n",
        "ë‚´ë¶€ì ìœ¼ë¡œ softmax í•¨ìˆ˜ ì ìš©.\n",
        "- input: logit score vector\n",
        "- output: class index. `dtype=long(int64)`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "OsY8asbLSoOW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02911d8c-1e65-4cab-ac3b-cb3f247e3fc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.int64\n",
            "CrossEntropyLoss: 0.74\n"
          ]
        }
      ],
      "source": [
        "# ì›ì‹œ ì¶œë ¥ê°’ (softmax í™œì„±í™” ì ìš© ì „)\n",
        "raw_outputs = torch.tensor(\n",
        "\t[[1.0, 2.0, 3.0],\n",
        "         [1.0, 2.0, 0.0],\n",
        "         [0.0, 2.0, 1.0]],\n",
        "        requires_grad=True).float()\n",
        "targets = torch.tensor([2, 0, 1]).long()  # ê° ìƒ˜í”Œì˜ í´ë˜ìŠ¤ ì¸ë±ìŠ¤\n",
        "print(targets.dtype)\n",
        "# CrossEntropyLoss ì„ ì–¸\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# ì†ì‹¤ ê³„ì‚° (softmax ë‚´ë¶€ ì ìš©)\n",
        "loss = criterion(raw_outputs, targets)\n",
        "print(f'CrossEntropyLoss: {loss.item():.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Drv_YTj-S35R"
      },
      "source": [
        "## NLLLoss\n",
        "Negative Log Likelihood Loss\n",
        "- ì£¼ë¡œ LogSoftmaxì™€ í•¨ê»˜ ì‚¬ìš©ë¨.\n",
        "- input: log í™•ë¥ \n",
        "- output: class index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Ugm5BaicS81v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26dd4e01-9771-4e86-b6b0-513c4f37d49e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLLLoss with LogSoftmax: 0.80\n"
          ]
        }
      ],
      "source": [
        "# ëª¨ë¸ ì¶œë ¥\n",
        "logits = torch.tensor(\n",
        "\t[[0.1, 0.2, 0.7], # max idx 2\n",
        "     \t [0.8, 0.1, 0.1], # max idx 0\n",
        "     \t [0.3, 0.5, 0.2]], # max idx 1\n",
        "    \trequires_grad=True).float()\n",
        "\n",
        "# íƒ€ê²Ÿ í´ë˜ìŠ¤ ì¸ë±ìŠ¤\n",
        "targets = torch.tensor([2, 0, 1]).long()\n",
        "\n",
        "# ë¡œê·¸ ì†Œí”„íŠ¸ë§¥ìŠ¤ ì ìš©\n",
        "log_softmax = F.log_softmax(logits, dim=1)\n",
        "\n",
        "# NLLLoss ì„ ì–¸\n",
        "criterion = nn.NLLLoss()\n",
        "loss = criterion(log_softmax, targets)\n",
        "print(f'NLLLoss with LogSoftmax: {loss.item():.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multiple-label Classification"
      ],
      "metadata": {
        "id": "BEY06cQDoSGw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MultiLabelSoftMarginLoss\n",
        "### Multi-label Classificationì„ ìœ„í•œ loss function.\n",
        "- í•˜ë‚˜ì˜ sampleì´ ì—¬ëŸ¬ ê°œì˜ classì— ë™ì‹œì— ì†í•  ìˆ˜ ìˆëŠ” classification.\n",
        "- ê° í´ë˜ìŠ¤ ë ˆì´ë¸”ì„ ê°ê° ë…ë¦½ì ì¸ binary classificationìœ¼ë¡œ ì·¨ê¸‰.\n",
        "- input: modelì˜ logit vector output(í´ë˜ìŠ¤ ê°ê°ì˜ ì˜ˆì¸¡ê°’)\n",
        "- ë‚´ë¶€ì ìœ¼ë¡œ logistic functionì„ ì ìš©í•˜ì—¬ ì´ë¥¼ [0, 1] ë²”ìœ„ì˜ í™•ë¥ ë¡œ ë³€í™˜.\n",
        "- ì´ ë³€í™˜ëœ í™•ë¥ ê³¼ ì‹¤ì œ ë ˆì´ë¸”ì˜ ê°’ì„ ì‚¬ìš©í•´ binary cross entropy loss ê³„ì‚°í•´ í•©ì¹¨."
      ],
      "metadata": {
        "id": "NmZx-0XwA40_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Formula\n",
        "$$L(y, \\hat y)\n",
        " = -\\cfrac1C \\displaystyle \\sum^C_{i=1} [y_i \\cdot \\log(\\sigma(\\hat y_i)) + (1-y_i)\\cdot \\log(1-\\sigma(\\hat y_i))]$$\n",
        "\n",
        "- ğœ: logistic function (~sigma)\n",
        "- ğ‘¦Ì‚_ğ‘–: predicted logit score.\n",
        "- ğ‘¦_ğ‘–: label or target."
      ],
      "metadata": {
        "id": "H5MHuFScUKcd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Class weight for imbalanced class\n",
        "ê° í´ë˜ìŠ¤ì— ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬í•  ìˆ˜ ìˆìŒ\n",
        "- íŠ¹ì • í´ë˜ìŠ¤ê°€ ë‹¤ë¥¸ í´ë˜ìŠ¤ë³´ë‹¤ ì¤‘ìš”\n",
        "- ë°ì´í„°ì…‹ì—ì„œ í´ë˜ìŠ¤ ë¶ˆê· í˜•ì„ í•´ì†Œí•  í•„ìš”ê°€ ìˆì„ ë•Œ ìœ ìš©"
      ],
      "metadata": {
        "id": "opT-r9uFUq4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logits = torch.tensor([[0.5, -1.0, 3.0], [1.5, -2.0, 0.0]], requires_grad=True)\n",
        "labels = torch.tensor([[1, 0, 1], [0, 1, 0]], dtype=torch.float)\n",
        "\n",
        "weights = torch.tensor([0.5, 2.0, 1.5], dtype=torch.float) # class ë³„ ì¤‘ìš”ë„\n",
        "\n",
        "loss_func = nn.MultiLabelSoftMarginLoss(weight=weights)\n",
        "\n",
        "loss = loss_func(logits, labels)\n",
        "print(\"Loss:\", loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtXT8wgKB9WZ",
        "outputId": "e5db3b52-c8c6-4708-ef56-01006670bf76"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 1.1801210641860962\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sigmoid+BCELossì™€ì˜ ì°¨ì´ì \n",
        "| | MultiLabelSoftMarginLoss|BCELoss|\n",
        "|---|---|---|\n",
        "|sigmoid|ë‚´ë¶€|ì™¸ë¶€ì—ì„œ í•„ìš”|\n",
        "|classification|multi-label|binary|\n",
        "|input|logit|probability|\n"
      ],
      "metadata": {
        "id": "pOrHX19oVakz"
      }
    }
  ]
}