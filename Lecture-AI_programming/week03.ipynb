{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyONHb+8g0Bwer3C54Fr9sgW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/9-coding/PyTorch/blob/main/Lecture-AI_programming/week03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Week 3\n",
        "# Transpose & Permute\n",
        "\n"
      ],
      "metadata": {
        "id": "-WRNkknObipX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lsn8YRLpbeEQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for c in [np, torch, tf]:\n",
        "  print(c.__name__, c.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yO5_xzTHbsSP",
        "outputId": "36f0a82b-c189-4472-ddd0-c2ed7774c89f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numpy 1.25.2\n",
            "torch 2.2.1+cu121\n",
            "tensorflow 2.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transpose\n",
        "- 전치 행렬. 행과 열을 바꾸는 처리.\n",
        "- Tensor의 경우 여러 축을 가지는데, 이것 중 2개 축의 위치를 바꾼다.\n",
        "<hr>\n",
        "- numpy/pytorch: axis만 변경됐을 뿐 여전히 같은 데이터를 공유하므로 새로운 tensor에서 데이터를 변경할 경우 원래의 tensor도 데이터가 반영된다.\n",
        "- tensorflow: tensor가 immutable이므로 transpose하면 다른 tensor가 생성되므로 영향을 미치지 않음."
      ],
      "metadata": {
        "id": "wXvauYlQbt0Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NumPy"
      ],
      "metadata": {
        "id": "i-8AQVXJb24l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.random.rand(2, 3)\n",
        "t1 = np.transpose(a)\n",
        "t2 = a.T\n",
        "print(a.shape)\n",
        "print(t1.shape)\n",
        "print(t2.shape)\n",
        "\n",
        "t2[0,1] = 77\n",
        "print(a[1,0])\n",
        "print(t1[0,1])\n",
        "print(t2[0,1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VeHl9a1b6VS",
        "outputId": "45025afb-8782-4ae0-8d79-08d23ae0c16b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 3)\n",
            "(3, 2)\n",
            "(3, 2)\n",
            "77.0\n",
            "77.0\n",
            "77.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PyTorch"
      ],
      "metadata": {
        "id": "BDx8srqIb7gn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a_torch = torch.rand(2, 3)\n",
        "t1_torch = torch.transpose(a_torch, 0, 1) #axis-0 (행) 과 axis-1 (열)을 교체.\n",
        "t2_torch = a_torch.T\n",
        "print(a_torch.shape)  #torch.Size([2,3])\n",
        "print(t1_torch.shape) #torch.Size([3,2])\n",
        "print(t2_torch.shape) #torch.Size([3,2])\n",
        "\n",
        "t2_torch[0,1] = 77\n",
        "print(a_torch[1,0])  # tensor(77.)\n",
        "print(t1_torch[0,1]) # tensor(77.)\n",
        "print(t2_torch[0,1]) # tensor(77.)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7TPvSbMb832",
        "outputId": "d67e8764-30ad-4669-ced6-d8737b64e915"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3])\n",
            "torch.Size([3, 2])\n",
            "torch.Size([3, 2])\n",
            "tensor(77.)\n",
            "tensor(77.)\n",
            "tensor(77.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TensorFlow"
      ],
      "metadata": {
        "id": "ry9iuuzYcACR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a_tf = tf.random.normal([2, 3])\n",
        "t1_tf = tf.transpose(a_tf)\n",
        "t2_tf = tf.transpose(a_tf, perm=[1, 0]) # T 지원안함.\n",
        "print(a_tf.shape, a_tf.dtype)\n",
        "print(t1_tf.shape, t1_tf.dtype)\n",
        "print(t2_tf.shape, t2_tf.dtype)\n",
        "\n",
        "indices = tf.constant([[0, 1]]) # (2, 2) 위치를 변경하고자 함\n",
        "updates = tf.constant([77], dtype=tf.float32) # 해당 위치에 넣고 싶은 값\n",
        "t2_tf = tf.tensor_scatter_nd_update(t2_tf, indices, updates)\n",
        "print(a_tf[1,0])\n",
        "print(t1_tf[0,1])\n",
        "print(t2_tf[0,1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2jr3V0EcBlT",
        "outputId": "c39f6b80-fbc6-4cdf-9312-d03d760fc5b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 3) <dtype: 'float32'>\n",
            "(3, 2) <dtype: 'float32'>\n",
            "(3, 2) <dtype: 'float32'>\n",
            "tf.Tensor(0.43915224, shape=(), dtype=float32)\n",
            "tf.Tensor(0.43915224, shape=(), dtype=float32)\n",
            "tf.Tensor(77.0, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Permute\n",
        "- tensor 축들의 순서를 임의로 바꿈\n",
        "- transpose와 달리 임의의 수의 축들을 임의의 순서로 자유롭게 변경 가능.\n",
        "- numpy, tensorflow는 transpose 통해 permute 구현."
      ],
      "metadata": {
        "id": "FtTArmeicGLF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NumPy"
      ],
      "metadata": {
        "id": "WPKubGMVcH14"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.random.rand(2, 3, 4)\n",
        "t1 = np.transpose(a, (0, 2, 1)) # 기존의 axis 0,1,2 순서를 axis 0,2,1 순서로 변경.\n",
        "print(a.shape)  # (2,3,4)\n",
        "print(t1.shape) # (2,4,3)\n",
        "t1[0,1,2] = 77\n",
        "print(a[0,2,1])  # 77.0\n",
        "print(t1[0,1,2]) # 77.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwrA89pvcK_O",
        "outputId": "111cb42d-31d7-4e87-ad8b-5c6f7a6fde1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 3, 4)\n",
            "(2, 4, 3)\n",
            "77.0\n",
            "77.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PyTorch"
      ],
      "metadata": {
        "id": "XLZuSoyncNZ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a_torch = torch.rand(2, 3, 4)\n",
        "t1_torch = torch.permute(a_torch, (0, 2, 1)) # numpy의 transpose와 사용방법이 유사.\n",
        "print(a_torch.shape)  # torch.Size([2, 3, 4])\n",
        "print(t1_torch.shape) # torch.Size([2, 4, 3])\n",
        "t1_torch[0,1,2] = 77\n",
        "print(a_torch[0,2,1])  # tensor(77.)\n",
        "print(t1_torch[0,1,2]) # tensor(77.)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUCeWcLNcN84",
        "outputId": "6ca8109a-2158-4be7-b7f6-baa37c9d40e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 4])\n",
            "torch.Size([2, 4, 3])\n",
            "tensor(77.)\n",
            "tensor(77.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TensorFlow"
      ],
      "metadata": {
        "id": "uPmh0IdLcPRk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a_tf = tf.random.normal([2, 3, 4])\n",
        "t1_tf = tf.transpose(a_tf, perm=[0, 2, 1]) #perm 이라는 키워드로 변경될 축의 순서를 기재.\n",
        "print(a_tf.shape)  # (2, 3, 4)\n",
        "print(t1_tf.shape) # (2, 4, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13gRAo-CcWNt",
        "outputId": "d48c2f35-e0cd-4e87-c824-80644e509452"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 3, 4)\n",
            "(2, 4, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensor Storage\n",
        "Tensor 인스턴스의 실제 데이터가 저장되는 1D numerical array 관리\n",
        "- 여러 인스턴스들이 같은 storage를 공유할 수 있음.\n",
        "- cpu 또는 gpu 등의 memory의 실제 data가 저장된 contiguous block 관리.\n",
        "- 다양한 shape의 Tensor 인스턴스들은 자신의 storage 인스턴스를 통해 data block을 관리함."
      ],
      "metadata": {
        "id": "Vr_SVCg3ssmR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "x = torch.randn(3,3)\n",
        "\n",
        "print(x.storage())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scCD8JJZsw9f",
        "outputId": "eb5f7dd3-34d6-4e9b-bb26-fd65960068ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " -0.41986027359962463\n",
            " -0.8027663230895996\n",
            " -1.3224666118621826\n",
            " -0.945031464099884\n",
            " -1.1443856954574585\n",
            " 0.6893463730812073\n",
            " -1.1195076704025269\n",
            " -0.12586873769760132\n",
            " -0.40938544273376465\n",
            "[torch.storage.TypedStorage(dtype=torch.float32, device=cpu) of size 9]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-42-7a8fb5f03ade>:5: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  print(x.storage())\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 실제 data가 저장되는 memory를 가리키는 위치를 반환하는 메서드 가짐."
      ],
      "metadata": {
        "id": "mMiX-0eKszUk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "a = torch.tensor([range(i,i+3) for i in [0,3,6]])\n",
        "a_sub = a[1:,0] # 부분에 대한 view\n",
        "\n",
        "# Tensor a 와 a_sub 의 contiguous 여부 확인.\n",
        "print(a.is_contiguous(), a_sub.is_contiguous())\n",
        "\n",
        "# Tensor a 와 a_sub 가 같은 메모리의 데이터를 공유하는지 여부.\n",
        "print(a.storage().data_ptr() == a_sub.storage().data_ptr())\n",
        "\n",
        "# Storage 인스턴스는 각 Tensor 인스턴스 별로 생성됨.\n",
        "print(id(a.storage()) == id(a_sub.storage()))\n",
        "\n",
        "# Tensor 인스턴스의 meta data\n",
        "print(f\"{a.shape=}, {a.size()=}, {a.stride()=}, {a.storage_offset()=}\")\n",
        "print(f\"{a_sub.shape=}, {a_sub.size()=}, {a_sub.stride()=}, {a_sub.storage_offset()=}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbn05Qy-s0Sk",
        "outputId": "c8f5c7ab-eb70-4af6-b143-8adbea21f987"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True False\n",
            "True\n",
            "True\n",
            "a.shape=torch.Size([3, 3]), a.size()=torch.Size([3, 3]), a.stride()=(3, 1), a.storage_offset()=0\n",
            "a_sub.shape=torch.Size([2]), a_sub.size()=torch.Size([2]), a_sub.stride()=(3,), a_sub.storage_offset()=3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `stride`: 각 축에서 index가 증가할 때 건너뛰어야하는 객체의 수.\n",
        "- `storage_offset`: 현재 Tensor 인스턴스가 Storage가 관리하는 memory block에서 몇 번째 객체에서 시작하는지를 나타냄.  "
      ],
      "metadata": {
        "id": "HKIXaQg8s2FH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Contiguous 확인"
      ],
      "metadata": {
        "id": "-2VNEDABs29j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([ range(i,i+3) for i in [0,3,6]])\n",
        "print(a)\n",
        "print(a.storage())\n",
        "print(a.is_contiguous())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1DcgeXjs2bI",
        "outputId": "536f7de8-9e8d-444e-eb22-0a10674ee9b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5],\n",
            "        [6, 7, 8]])\n",
            " 0\n",
            " 1\n",
            " 2\n",
            " 3\n",
            " 4\n",
            " 5\n",
            " 6\n",
            " 7\n",
            " 8\n",
            "[torch.storage.TypedStorage(dtype=torch.int64, device=cpu) of size 9]\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a_sub = a[1:,0]\n",
        "print(a_sub)\n",
        "print(a_sub.storage())\n",
        "print(a_sub.is_contiguous())\n",
        "print(a.storage().data_ptr() == a_sub.storage().data_ptr())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FarSgfgis5el",
        "outputId": "1b637a9d-f9da-48df-a3f8-bf5ba7d624b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3, 6])\n",
            " 0\n",
            " 1\n",
            " 2\n",
            " 3\n",
            " 4\n",
            " 5\n",
            " 6\n",
            " 7\n",
            " 8\n",
            "[torch.storage.TypedStorage(dtype=torch.int64, device=cpu) of size 9]\n",
            "False\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## View / Reshape\n",
        "\n",
        "view: instance가 contiguous한 경우에만 사용 가능.<br>\n",
        "reshape: <br>\n",
        "- contiguous한 경우 view와 같은 동작.\n",
        "- 아닌 경우엔 contiguous() 메서드를 호출하고 view를 수행한 것에 해당함. (이 경우  underlying memory block이 새로 만들어짐.)\n",
        "- 따라서 memory를 공유할 수도 아닐 수도 있음.\n"
      ],
      "metadata": {
        "id": "4UWm8854s7ch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a_r = a.reshape((9,))\n",
        "a_r[3] = 777\n",
        "print('데이터 저장공간을 share함.')\n",
        "print('a_r: af.reshape')\n",
        "print(a_r)\n",
        "print('a: orginal')\n",
        "print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRNNAry5s-VD",
        "outputId": "06fd659a-4884-44df-9798-8ab35b70135c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "데이터 저장공간을 share함.\n",
            "a_r: af.reshape\n",
            "tensor([  0,   1,   2, 777,   4,   5,   6,   7,   8])\n",
            "a: orginal\n",
            "tensor([[  0,   1,   2],\n",
            "        [777,   4,   5],\n",
            "        [  6,   7,   8]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transpose / Permute\n",
        "- underlying data 를 공유하여 Tensor 인스턴스의 meta data (stride 등)을 수정한다.\n",
        "- 단, 이를 통해 얻어진 인스턴스에서는\n",
        "contiguous는 깨지게 된다.\n",
        "- contiguous 메서드 호출을 하여 해당 인스턴스의 meta data를 기반으로 Tensor 인스턴스를 새로 얻는 경우에는 새로운 underlying data가 만들어지게 된다."
      ],
      "metadata": {
        "id": "C421YKeGs_f4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a_t = torch.transpose(a,0,1)\n",
        "print(a_t)\n",
        "print(a_t.storage())\n",
        "print(a_t.is_contiguous())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvKsIwQZtAvd",
        "outputId": "ca981f2d-bd17-4f8e-c9de-9a64829b5421"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  0, 777,   6],\n",
            "        [  1,   4,   7],\n",
            "        [  2,   5,   8]])\n",
            " 0\n",
            " 1\n",
            " 2\n",
            " 777\n",
            " 4\n",
            " 5\n",
            " 6\n",
            " 7\n",
            " 8\n",
            "[torch.storage.TypedStorage(dtype=torch.int64, device=cpu) of size 9]\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a_t[0,1] = 999\n",
        "print(a_t)\n",
        "print('-------')\n",
        "print(a)\n",
        "print('-------')\n",
        "print(a_sub)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g88clzKOtCne",
        "outputId": "1fe8f543-7e27-4d4d-ea28-6e94a909a9e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  0, 999,   6],\n",
            "        [  1,   4,   7],\n",
            "        [  2,   5,   8]])\n",
            "-------\n",
            "tensor([[  0,   1,   2],\n",
            "        [999,   4,   5],\n",
            "        [  6,   7,   8]])\n",
            "-------\n",
            "tensor([3, 6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "act = a_t.contiguous()\n",
        "print(act)\n",
        "print(act.storage())\n",
        "act[1] = 999\n",
        "print(act)\n",
        "print(a_t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXBXav1htDdg",
        "outputId": "d3266996-752e-4afe-f061-89ba1d0fdacc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  0, 999,   6],\n",
            "        [  1,   4,   7],\n",
            "        [  2,   5,   8]])\n",
            " 0\n",
            " 999\n",
            " 6\n",
            " 1\n",
            " 4\n",
            " 7\n",
            " 2\n",
            " 5\n",
            " 8\n",
            "[torch.storage.TypedStorage(dtype=torch.int64, device=cpu) of size 9]\n",
            "tensor([[  0, 999,   6],\n",
            "        [999, 999, 999],\n",
            "        [  2,   5,   8]])\n",
            "tensor([[  0, 999,   6],\n",
            "        [  1,   4,   7],\n",
            "        [  2,   5,   8]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a_t_r = a_t.reshape((9,)) # uncontiguous tensor에서는 새로 생성이 이루어짐.\n",
        "print(a_t_r)\n",
        "a_t_r[1] = 999\n",
        "print(a_t_r)\n",
        "print(a_t) # 달라짐."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaY5g7PQtFSD",
        "outputId": "ab58b1f6-c0fc-47f3-b024-a743f444de59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([  0, 999,   6,   1,   4,   7,   2,   5,   8])\n",
            "tensor([  0, 999,   6,   1,   4,   7,   2,   5,   8])\n",
            "tensor([[  0, 999,   6],\n",
            "        [  1,   4,   7],\n",
            "        [  2,   5,   8]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(a)\n",
        "print('------')\n",
        "print('permute axis-0 and axis-1 = transpose')\n",
        "ap = a.permute([1,0]) # permute axis-0 and axis-1\n",
        "print(ap)\n",
        "print(a.storage().data_ptr() == ap.storage().data_ptr())\n",
        "print(ap.is_contiguous())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZewmjBptHL-",
        "outputId": "defa0577-d36b-4b4a-cd7f-49627ccb8da1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  0,   1,   2],\n",
            "        [999,   4,   5],\n",
            "        [  6,   7,   8]])\n",
            "------\n",
            "permute axis-0 and axis-1 = transpose\n",
            "tensor([[  0, 999,   6],\n",
            "        [  1,   4,   7],\n",
            "        [  2,   5,   8]])\n",
            "True\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{a.shape=}, {a.size()=}, {a.stride()=}, {a.storage_offset()=}\")\n",
        "print(f\"{a_t.shape=}, {a_t.size()=}, {a_t.stride()=}, {a_t.storage_offset()=}\")\n",
        "print(f\"{a_sub.shape=}, {a_sub.size()=}, {a_sub.stride()=}, {a_sub.storage_offset()=}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZmLyZeDtIXL",
        "outputId": "7c4597f0-70de-4d2f-da28-650c12fbab98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a.shape=torch.Size([3, 3]), a.size()=torch.Size([3, 3]), a.stride()=(3, 1), a.storage_offset()=0\n",
            "a_t.shape=torch.Size([3, 3]), a_t.size()=torch.Size([3, 3]), a_t.stride()=(1, 3), a_t.storage_offset()=0\n",
            "a_sub.shape=torch.Size([2]), a_sub.size()=torch.Size([2]), a_sub.stride()=(3,), a_sub.storage_offset()=3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# view, data, and detach"
      ],
      "metadata": {
        "id": "0rVGoIXKcgld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_tensor_info(tensor):\n",
        "  info = []\n",
        "  for name in ['requires_grad', 'is_leaf', 'retains_grad', 'grad_fn', 'grad']:\n",
        "    info.append(f'{name}({getattr(tensor, name, None)})')\n",
        "  info.append(f'\\ntensor{str(tensor)}')\n",
        "  return ' '.join(info)"
      ],
      "metadata": {
        "id": "juDNi21TclOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## tensor.view()\n",
        "**tensor 인스턴스의 dimension 수정에 사용.**\n",
        "- 원본 tensor 인스턴스 데이터가 contiguous해야 함.\n",
        "- 이 메서드는 새로운 shape를 가진 같은 데이터의 새로운 tensor 인스턴스를 반환하지만, 원본 tensor 인스턴스와 underlying memory를 공유하여 같은 데이터를 공유함.\n",
        "- 즉, 메모리를 재할당하지 않고 tensor의 shape와 각 축의 stride만이 바뀜."
      ],
      "metadata": {
        "id": "x0KcbYvvcmUD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# requires_grad=True는 이 텐서에 대한 연산을 추적해야 함을 의미\n",
        "a = torch.rand(12,requires_grad=True)\n",
        "print(f'{a.shape=}, {a.data_ptr()=}, \\n{a.is_contiguous()=}, {a.stride()=}\\n')\n",
        "\n",
        "a_view = a.view((2,3,2))\n",
        "print(f'a_view: {a_view.shape=}, {a_view.data_ptr()=}, \\n{a_view.is_contiguous()=}, {a_view.stride()=}\\n')\n",
        "\n",
        "a_view_t = a_view.transpose(0,1)\n",
        "print(f'a_view_t: {a_view_t.shape=}, {a_view_t.data_ptr()=}, \\n{a_view_t.is_contiguous()=}, {a_view_t.stride()=}\\n')\n",
        "\n",
        "a_other = a_view_t.contiguous()\n",
        "print(f'a_other: {a_other.shape=}, {a_other.data_ptr()=}, \\n{a_other.is_contiguous()=}, {a_other.stride()=}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3j1DYR1zcnXO",
        "outputId": "b89ecfdf-cb22-41b5-c39b-d7b92c61d9c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a.shape=torch.Size([12]), a.data_ptr()=97289610544384, \n",
            "a.is_contiguous()=True, a.stride()=(1,)\n",
            "\n",
            "a_view: a_view.shape=torch.Size([2, 3, 2]), a_view.data_ptr()=97289610544384, \n",
            "a_view.is_contiguous()=True, a_view.stride()=(6, 2, 1)\n",
            "\n",
            "a_view_t: a_view_t.shape=torch.Size([3, 2, 2]), a_view_t.data_ptr()=97289610544384, \n",
            "a_view_t.is_contiguous()=False, a_view_t.stride()=(2, 6, 1)\n",
            "\n",
            "a_other: a_other.shape=torch.Size([3, 2, 2]), a_other.data_ptr()=97289575683712, \n",
            "a_other.is_contiguous()=True, a_other.stride()=(4, 2, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## tensor.data\n",
        "**tensor 인스턴스의 데이터를 의미하는 attribute.**<br>\n",
        "tensor 인스턴스의 grad와 requires_grad와 같은 tensor의 메타데이터를 가지고 있지 않은 순수한 데이터를 의미.\n",
        "- 주로 autograd에서 미분 계산을 하지 않고 원본 데이터를 직접 조작할 때 사용.\n",
        "- 현재 tensor.data를 직접 접근하는 방식은 권장되지 않음.\n",
        "\n",
        "\n",
        "## tensor.detach\n",
        "- .detach()를 사용하여 계산 그래프에서 해당 텐서를 분리하면 gradient 계산에서 제외되나 여전히 데이터는 공유함.\n",
        "- tensor.data를 직접 수정할 경우, 계산 그래프의 무결성이 깨질 수 있으며 이는 예상치 못한 버그의 원인이 됨.\n",
        "\n",
        "직접적인 데이터 조작이 필요할 때는 계산 그래프에서 해당 텐선 인스턴스를 분리하는 .detach() 사용 권장"
      ],
      "metadata": {
        "id": "qTPcL28gcorw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "b = a*2.        #\n",
        "b.retain_grad() # leaf tensor가 아닌데도 grad를 확인하기 위해서 호출.\n",
        "\n",
        "c = b*3.        #\n",
        "c.retain_grad() # leaf tensor가 아닌데도 grad를 확인하기 위해서 호출.\n",
        "\n",
        "# .detach()를 사용하여 c 에서 더 이상 그래디언트가 전파되지 않도록 처리.\n",
        "c_detach = c.detach()\n",
        "# u 는 이제 그래디언트 계산에서 제외.\n",
        "# u 를 사용한 추가 연산도 수행 가능\n",
        "u = c_detach*2.  # u의 계산은 그래디언트 추적에서 제외됩니다.\n",
        "\n",
        "# 그러나 c에 대한 추가 연산은 detach되지않은 다른 tensor의 경우처럼 c의 gradient 계산에 영향.\n",
        "# 즉, c에 대해 또 다른 연산을 추가하고, 그 연산에 대한 gradient를 계산함.\n",
        "d = c * 2.\n",
        "d.retain_grad() # leaf tensor가 아닌데도 grad를 확인하기 위해서 호출.\n",
        "\n",
        "# d 에 대한 gradient를 계산.\n",
        "print('------------')\n",
        "d.backward(torch.ones(d.shape))\n",
        "\n",
        "\n",
        "print(a.grad) # 12\n",
        "print(b.grad) # 6\n",
        "print(c.grad) # 2\n",
        "print(d.grad) # 1\n",
        "\n",
        "# leaf이 아닌 tensor들에 대한 gradient를 보려면, retain_grad() 를 사용.\n",
        "for c_tensor in [a,b,c,d]:\n",
        "  c_grad = c_tensor.grad\n",
        "  if c_grad != None:\n",
        "    c_grad.zero_()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Y8oO91vcqqW",
        "outputId": "e21c9f38-3ece-4261-d1a4-27ad1d83419f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------\n",
            "tensor([12., 12., 12., 12., 12., 12., 12., 12., 12., 12., 12., 12.])\n",
            "tensor([6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6.])\n",
            "tensor([2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.])\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# require_grad 기능을 켠 tensor는 일반적인 numpy 객체를 얻거나 matplotflib에서 사용할 수 없으나 detach를 사용하면 가능.\n",
        "a_detach = a.detach().numpy() # a와 여전히 underlying memory를 공유.\n",
        "d_detach = d.detach().numpy() # b와 여전히 underlying memory를 공유.\n",
        "\n",
        "fig, axis = plt.subplots(1,1)\n",
        "axis.plot(a_detach,d_detach)\n",
        "axis.grid()\n",
        "# axis.set_xlim(a_detach.min(),a_detach.max())\n",
        "# axis.set_ylim(d_detach.min(),d_detach.max())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "-dJhvNqTcs-o",
        "outputId": "edbb03e3-f543-4df8-807b-3097acaa1375"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c_detach[0] = 100\n",
        "print(c) # c도 변경됨.\n",
        "\n",
        "# underlying memory같음을 확인.\n",
        "print(c.data_ptr())\n",
        "print(c.detach().data_ptr())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2bq3OVBcvc2",
        "outputId": "ccc02057-8015-4925-989c-b7157d561c70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([100.0000,   5.8931,   1.2404,   1.1902,   5.6497,   1.0134,   0.8002,\n",
            "          3.2194,   0.1328,   2.2997,   2.9492,   2.2205],\n",
            "       grad_fn=<MulBackward0>)\n",
            "97289613601920\n",
            "97289613601920\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for cur in [a,b,c,d]:\n",
        "  print(get_tensor_info(cur))\n",
        "  print('------------------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVLEs6GIc28V",
        "outputId": "51fab95b-bfd1-4ad4-c670-37240debd395"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "requires_grad(True) is_leaf(True) retains_grad(False) grad_fn(None) grad(tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])) \n",
            "tensortensor([0.1626, 0.9822, 0.2067, 0.1984, 0.9416, 0.1689, 0.1334, 0.5366, 0.0221,\n",
            "        0.3833, 0.4915, 0.3701], requires_grad=True)\n",
            "------------------\n",
            "requires_grad(True) is_leaf(False) retains_grad(True) grad_fn(<MulBackward0 object at 0x7800cad46830>) grad(tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])) \n",
            "tensortensor([0.3253, 1.9644, 0.4135, 0.3967, 1.8832, 0.3378, 0.2667, 1.0731, 0.0443,\n",
            "        0.7666, 0.9831, 0.7402], grad_fn=<MulBackward0>)\n",
            "------------------\n",
            "requires_grad(True) is_leaf(False) retains_grad(True) grad_fn(<MulBackward0 object at 0x7800c8c08070>) grad(tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])) \n",
            "tensortensor([100.0000,   5.8931,   1.2404,   1.1902,   5.6497,   1.0134,   0.8002,\n",
            "          3.2194,   0.1328,   2.2997,   2.9492,   2.2205],\n",
            "       grad_fn=<MulBackward0>)\n",
            "------------------\n",
            "requires_grad(True) is_leaf(False) retains_grad(True) grad_fn(<MulBackward0 object at 0x7800cad46aa0>) grad(tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])) \n",
            "tensortensor([ 1.9515, 11.7862,  2.4808,  2.3805, 11.2995,  2.0267,  1.6005,  6.4389,\n",
            "         0.2655,  4.5994,  5.8984,  4.4411], grad_fn=<MulBackward0>)\n",
            "------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Find maximum and minimum from tensor"
      ],
      "metadata": {
        "id": "yy09C5mMdFrC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rng = np.random.default_rng(seed=23)\n",
        "ori = rng.random((3,2)).astype(np.float32)\n",
        "print(ori)\n",
        "\n",
        "a_np = ori.copy()\n",
        "a_torch = torch.tensor(ori)\n",
        "a_tf = tf.Variable(ori)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pxu_CEqbdJsG",
        "outputId": "c6b97a83-8684-4239-cc17-d90ed901f4aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.69393307 0.6414582 ]\n",
            " [0.12864423 0.11370805]\n",
            " [0.6533455  0.8534571 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NumPy\n",
        "- np.max 와 np.min 함수를 이용하여 최대, 최소인 값을 구함.\n",
        "- 특정 축을 axis parameter로 지정하여 구할 수 있음 (결과는 해당 axis가 1이 됨.)\n",
        "- np.argmax 와 np.argmin 함수를 이용하여 최대, 최소인 값의 index를 반환함."
      ],
      "metadata": {
        "id": "VfzMM9x7dRKo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"max\")\n",
        "print(np.max(a_np)) # 전체\n",
        "print(np.max(a_np, 0)) # row\n",
        "print(np.max(a_np, 1)) # column\n",
        "\n",
        "print(\"\\nmin\")\n",
        "print(np.min(a_np)) # 전체\n",
        "print(np.min(a_np, 0)) # row\n",
        "print(np.min(a_np, 1)) # column\n",
        "\n",
        "print(\"\\nargmax\")\n",
        "print(np.argmax(a_np)) # 전체\n",
        "print(np.argmax(a_np, 0)) # row\n",
        "print(np.argmax(a_np, 1)) # column\n",
        "\n",
        "print(\"\\nargmin\")\n",
        "print(np.argmin(a_np)) # 전체\n",
        "print(np.argmin(a_np, 0)) # row\n",
        "print(np.argmin(a_np, 1)) # column"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bj7DHPWtdRu-",
        "outputId": "1d96da00-1ee9-42a8-f199-e099f52401f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max\n",
            "0.8534571\n",
            "[0.69393307 0.8534571 ]\n",
            "[0.69393307 0.12864423 0.8534571 ]\n",
            "\n",
            "min\n",
            "0.11370805\n",
            "[0.12864423 0.11370805]\n",
            "[0.6414582  0.11370805 0.6533455 ]\n",
            "\n",
            "argmax\n",
            "5\n",
            "[0 2]\n",
            "[0 0 1]\n",
            "\n",
            "argmin\n",
            "3\n",
            "[1 1]\n",
            "[1 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PyTorch\n",
        "\n",
        "`torch.max`와 `torch.min` 함수를 사용하여 최대값과 최소값을 구함.\n",
        "\n",
        "- 특정 축을 `dim` parameter로 지정하여 구할 수 있음.\n",
        "- 특정 축을 지정할 경우, `torch.max`와 `torch.min`은 indices를 같이 반환함.\n",
        "- `torch.argmax` 와 `torch.argmin` 함수를 이용하여 최대, 최소값의 indices를 반환함."
      ],
      "metadata": {
        "id": "EpvXE8YVdTaP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"max\")\n",
        "print(torch.max(a_torch)) # 축을 지정하지 않으면 값만 반환\n",
        "print(torch.max(a_torch, 0)) # row\n",
        "print(torch.max(a_torch, 1)) # column\n",
        "\n",
        "print(\"\\nmin\")\n",
        "print(torch.min(a_torch)) # 축을 지정하지 않으면 값만 반환\n",
        "print(torch.min(a_torch, 0)) # row\n",
        "print(torch.min(a_torch, 1)) # column\n",
        "\n",
        "print(\"\\nargmax\")\n",
        "print(torch.argmax(a_torch)) # 축을 지정하지 않으면 값만 반환\n",
        "print(torch.argmax(a_torch, 0)) # row\n",
        "print(torch.argmax(a_torch, 1)) # column\n",
        "\n",
        "print(\"\\nargmin\")\n",
        "print(torch.argmin(a_torch)) # 축을 지정하지 않으면 값만 반환\n",
        "print(torch.argmin(a_torch, 0)) # row\n",
        "print(torch.argmin(a_torch, 1)) # column"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2zeMfbjdU4c",
        "outputId": "3ecba5b7-1254-49ec-a3cc-e1af523f6089"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max\n",
            "tensor(0.8535)\n",
            "torch.return_types.max(\n",
            "values=tensor([0.6939, 0.8535]),\n",
            "indices=tensor([0, 2]))\n",
            "torch.return_types.max(\n",
            "values=tensor([0.6939, 0.1286, 0.8535]),\n",
            "indices=tensor([0, 0, 1]))\n",
            "\n",
            "min\n",
            "tensor(0.1137)\n",
            "torch.return_types.min(\n",
            "values=tensor([0.1286, 0.1137]),\n",
            "indices=tensor([1, 1]))\n",
            "torch.return_types.min(\n",
            "values=tensor([0.6415, 0.1137, 0.6533]),\n",
            "indices=tensor([1, 1, 0]))\n",
            "\n",
            "argmax\n",
            "tensor(5)\n",
            "tensor([0, 2])\n",
            "tensor([0, 0, 1])\n",
            "\n",
            "argmin\n",
            "tensor(3)\n",
            "tensor([1, 1])\n",
            "tensor([1, 1, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TensorFlow\n",
        "\n",
        "`tf.reduce_max`와 `tf.reduce_min` 함수를 사용하여 최대값과 최소값을 구함.\n",
        "\n",
        "- 특정 축을 따라 구할 경우엔, `axis` parameter로 지정.\n",
        "- torch.argmax 와 torch.argmin 함수를 이용하여 최대, 최소값의 indices를 반환함."
      ],
      "metadata": {
        "id": "OPEnKyG7dWsy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"max\")\n",
        "print(tf.reduce_max(a_tf)) # 전체\n",
        "print(tf.reduce_max(a_tf, 0))\n",
        "print(tf.reduce_max(a_tf, 1))\n",
        "\n",
        "print(\"\\nmin\")\n",
        "print(tf.reduce_min(a_tf))\n",
        "print(tf.reduce_min(a_tf, 0))\n",
        "print(tf.reduce_min(a_tf, 1))\n",
        "\n",
        "print(\"\\nargmax\")\n",
        "print(tf.argmax(a_tf))\n",
        "print(tf.argmax(a_tf, 0))\n",
        "print(tf.argmax(a_tf, 1))\n",
        "\n",
        "print(\"\\nargmin\")\n",
        "print(tf.argmin(a_tf))\n",
        "print(tf.argmin(a_tf, 0))\n",
        "print(tf.argmin(a_tf, 1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tO5jQ3o_dX6F",
        "outputId": "5c2b0093-f66b-4e1b-ed4a-42bb85e862cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max\n",
            "tf.Tensor(0.8534571, shape=(), dtype=float32)\n",
            "tf.Tensor([0.69393307 0.8534571 ], shape=(2,), dtype=float32)\n",
            "tf.Tensor([0.69393307 0.12864423 0.8534571 ], shape=(3,), dtype=float32)\n",
            "\n",
            "min\n",
            "tf.Tensor(0.11370805, shape=(), dtype=float32)\n",
            "tf.Tensor([0.12864423 0.11370805], shape=(2,), dtype=float32)\n",
            "tf.Tensor([0.6414582  0.11370805 0.6533455 ], shape=(3,), dtype=float32)\n",
            "\n",
            "argmax\n",
            "tf.Tensor([0 2], shape=(2,), dtype=int64)\n",
            "tf.Tensor([0 2], shape=(2,), dtype=int64)\n",
            "tf.Tensor([0 0 1], shape=(3,), dtype=int64)\n",
            "\n",
            "argmin\n",
            "tf.Tensor([1 1], shape=(2,), dtype=int64)\n",
            "tf.Tensor([1 1], shape=(2,), dtype=int64)\n",
            "tf.Tensor([1 1 0], shape=(3,), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a_np = rng.random((2,2,3)).astype(np.float32)\n",
        "a_np"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pq9CDcUHdbFa",
        "outputId": "2f602497-97a0-472e-9369-d0e05deebf83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.20177913, 0.21801864, 0.7165846 ],\n",
              "        [0.47069967, 0.41522193, 0.3491478 ]],\n",
              "\n",
              "       [[0.06385376, 0.45466617, 0.3014533 ],\n",
              "        [0.38907674, 0.5402978 , 0.6835897 ]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor(a_np)\n",
        "m = torch.max(a,2)\n",
        "print(m[0].shape)\n",
        "print(m[1].shape)\n",
        "m"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obIlOpnWdc4r",
        "outputId": "3175ff71-d138-45ea-dc22-502357465f1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 2])\n",
            "torch.Size([2, 2])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.return_types.max(\n",
              "values=tensor([[0.7166, 0.4707],\n",
              "        [0.4547, 0.6836]]),\n",
              "indices=tensor([[2, 0],\n",
              "        [1, 2]]))"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m = torch.max(a,1)\n",
        "print(m[0].shape, m[1].shape)\n",
        "m"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-Gto9vuddry",
        "outputId": "e3803e54-4f1c-4c58-a6cf-03e7d6eae93e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3]) torch.Size([2, 3])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.return_types.max(\n",
              "values=tensor([[0.4707, 0.4152, 0.7166],\n",
              "        [0.3891, 0.5403, 0.6836]]),\n",
              "indices=tensor([[1, 1, 0],\n",
              "        [1, 1, 1]]))"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a_p = torch.permute(a, [0,2,1])\n",
        "a_p"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-scwyDC-deeF",
        "outputId": "864a76cf-1a2d-4db0-d4bb-3941b7758233"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.2018, 0.4707],\n",
              "         [0.2180, 0.4152],\n",
              "         [0.7166, 0.3491]],\n",
              "\n",
              "        [[0.0639, 0.3891],\n",
              "         [0.4547, 0.5403],\n",
              "         [0.3015, 0.6836]]])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    }
  ]
}