{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOg4/sqdQTwBUmpgL3kAVlR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/9-coding/PyTorch/blob/main/Lecture-AI_programming/week09.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Week09"
      ],
      "metadata": {
        "id": "XNdqc3lr7vzj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-585wAP7sH-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "torch.nn.Module 객체의 state_dict() 메서드는\n",
        "\n",
        "- 모델의 학습 가능한 매개변수(가중치와 바이어스)의 상태와\n",
        "- 버퍼(예: BatchNorm의 running mean과 variance 등)의 상태를 저장하는\n",
        "- collections.OrderedDict 객체를 반환.\n",
        "- 반환된 객체는 모델의 현재 상태를 나타내며, 저장 및 로드가 가능함."
      ],
      "metadata": {
        "id": "XBeRoZTO7vhe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Serialization: 직렬화로 저장.\n",
        "개체 직렬화\n",
        "key: value 형태로"
      ],
      "metadata": {
        "id": "z0njj61E8RPW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. OrderedDict 형태:\n",
        "- state_dict()는 attribute 이름을 키로 하고,\n",
        "- 그에 대응하는 torch.Tensor를 값으로 갖는\n",
        "- collections.OrderedDict 객체를 반환.\n",
        "2. 학습 가능한 매개변수:\n",
        "- state_dict()는 torch.nn.Parameter 객체로 정의된 모든 학습 가능한 attributes를 포함.\n",
        "3. 버퍼:\n",
        "- 모델에 포함된 모든 버퍼(예: BatchNorm 계층의 running mean과 variance)도 포함."
      ],
      "metadata": {
        "id": "AcazBMfv-aWP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "OrderedDict: 순서가 정의된 딕셔너리 형태."
      ],
      "metadata": {
        "id": "XQpZBXIK-mn5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from collections import OrderedDict\n",
        "\n",
        "# 간단한 모델 정의\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.linear = nn.Linear(10, 5)\n",
        "        self.bn = nn.BatchNorm1d(5)\n",
        "        # self.sub = nn.Sequential(\n",
        "        #     OrderedDict({\n",
        "        #         'ds00_layer': nn.Linear(5,5),\n",
        "        #         'ds00_bn':nn.BatchNorm1d(5),\n",
        "        #         'ds00_act': nn.ReLU(),\n",
        "        #         'ds01_layer': nn.Linear(5,5),\n",
        "        #     })\n",
        "        # )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        x = self.bn(x)\n",
        "        return x\n",
        "\n",
        "# 모델 인스턴스 생성\n",
        "model = MyModel()\n",
        "\n",
        "# 모델의 state_dict 가져오기\n",
        "state_dict = model.state_dict()\n",
        "\n",
        "# state_dict 내용 출력\n",
        "for key, value in state_dict.items():\n",
        "    print(f\"{key}: {value.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9MhjrFL_4B4",
        "outputId": "78c7ce0b-cf01-429d-e113-dc613e130a41"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "linear.weight: torch.Size([5, 10])\n",
            "linear.bias: torch.Size([5])\n",
            "bn.weight: torch.Size([5])\n",
            "bn.bias: torch.Size([5])\n",
            "bn.running_mean: torch.Size([5])\n",
            "bn.running_var: torch.Size([5])\n",
            "bn.num_batches_tracked: torch.Size([])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델의 state_dict 가져오기\n",
        "state_dict0 = model.state_dict(prefix='ds', keep_vars=True)\n",
        "\n",
        "# state_dict 내용 출력\n",
        "for key, value in state_dict0.items():\n",
        "    print(f\"{key}: {value.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hwrwk23VE4m1",
        "outputId": "28f90b3e-9a76-4bbd-eecc-97a177a6d92d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dslinear.weight: torch.Size([5, 10])\n",
            "dslinear.bias: torch.Size([5])\n",
            "dsbn.weight: torch.Size([5])\n",
            "dsbn.bias: torch.Size([5])\n",
            "dsbn.running_mean: torch.Size([5])\n",
            "dsbn.running_var: torch.Size([5])\n",
            "dsbn.num_batches_tracked: torch.Size([])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "메서드 parameters: state_dict(desitnation=None, prefix='', keep_vars=False)\n",
        "keep_vars 는 기본값이 False로 buffers와 parameters 의 값만을 추출할지를 결정\n",
        "keep_vars=True 인 경우, 값 대신 tensor객체로 데이터 버퍼를 가지고 있는 dictionary가 반환됨.\n",
        "value 가 파라메터인 경우엔 Parameter 로 얻어지고,\n",
        "value 가 버퍼인 경우엔 Tensor 로 얻어짐.\n",
        "keep_vars=True 인 경우, 메모리 사용량이 커지고, 매우 느리고 복잡한 동작이 이루어지지만. 다음의 장점을 가짐.\n",
        "모델 디버깅: 모델 상태를 조사하고 특정 매개 변수나 버퍼의 값을 변경해야 하는 경우 유용\n",
        "모델 커스터마이징: 모델을 불러온 후 특정 매개 변수나 버퍼의 값을 변경해야 하는 경우 유용\n",
        "모델 저장 및 불러오기 확장: 모델 저장 및 불러오기 프로세스를 확장하고 추가적인 정보를 저장해야 하는 경우 유용\n",
        "하지만, PyTorch의 버전이 정확히 맞아야만 동작할 수 있는 등의 제한점을 가짐.\n",
        "저장의 용도로는 keep_vars=False를 사용하는 게 좋음.\n"
      ],
      "metadata": {
        "id": "wTj2Ev9SF9D4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "linear.weight: nn.Linear 계층의 가중치 파라미터\n",
        "linear.bias: nn.Linear 계층의 바이어스 파라미터\n",
        "bn.weight: nn.BatchNorm1d 계층의 가중치 파라미터\n",
        "bn.bias: nn.BatchNorm1d 계층의 바이어스 파라미터\n",
        "bn.running_mean: nn.BatchNorm1d 계층의 running mean 버퍼\n",
        "bn.running_var: nn.BatchNorm1d 계층의 running variance 버퍼\n",
        "bn.num_batches_tracked: nn.BatchNorm1d 계층에서 배치의 수를 추적하는 버퍼"
      ],
      "metadata": {
        "id": "rV27nStUHj2G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 저장\n",
        "\n",
        "state_dict를 파일에 저장하여 나중에 모델을 복원할 수 있음."
      ],
      "metadata": {
        "id": "AIXuEganHnjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "torch.save(model.state_dict(), 'model_state.pth')"
      ],
      "metadata": {
        "id": "HmO9XptYHlE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 로드:\n",
        "\n",
        "저장된 state_dict를 로드하여 모델을 복원."
      ],
      "metadata": {
        "id": "8jGxMXR8HsXj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyModel()\n",
        "model.load_state_dict(torch.load('model_state.pth'))\n",
        "model.eval() # 평가 모드로 전환 (선택 사항)`"
      ],
      "metadata": {
        "id": "MHmK38jSHt5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "파라미터 업데이트:\n",
        "\n",
        "state_dict를 사용하여 모델의 특정 파라미터를 업데이트할 수 있음."
      ],
      "metadata": {
        "id": "xfzWfOZeHvPW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "state_dict['linear.weight'] = torch.ones_like(state_dict['linear.weight'])\n",
        "model.load_state_dict(state_dict)"
      ],
      "metadata": {
        "id": "cw6mX_fEHxI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Torch: Save and Load Model\n",
        "PyTorch에서 model을 저장하는 방법은 크게 두 가지임.\n",
        "\n",
        "모델의 Parameters (= weights and bias)를 저장 (Structure 등은 저장되지 않음).\n",
        "model 전체를 저장하는 방법 (Parameters와 Structure 함께)\n",
        "일반적으로 권장되는 방법은 1번임.\n",
        "\n",
        "1번의 경우,\n",
        "\n",
        "비록 모델의 구조를 정의하고 있는 class 의 instance 코드 상에서 생성하고,\n",
        "이 instance로 로딩을 수행해줘야 하지만,\n",
        "해당 class의 소스를 정확히 가지고 있을 경우 PyTorch 버전 등에 상관없이\n",
        "이전과 동일한 모델을 load를 통해 얻을 수 있음.\n",
        "위에서 정확히 가지고 있다라는 애기는 save할 때와 load할 때의 모델 클래스의 definition이 동일해야함을 의미함."
      ],
      "metadata": {
        "id": "G1T65rU1JWxJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://ds31x.tistory.com/263"
      ],
      "metadata": {
        "id": "6vGPp_9EJZF_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 library와 모듈 import\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import init\n",
        "from collections import OrderedDict\n",
        "\n",
        "# 간단한 linear regression model 정의.\n",
        "# SimpleModel0와 SimpleModel1은\n",
        "# 똑같은 구조이나 파라메터들의 초기값만 다름.\n",
        "class SimpleModel0(nn.Module):\n",
        "\n",
        "  def __init__(self, n_in_f, n_out_f):\n",
        "\n",
        "    super().__init__()\n",
        "\n",
        "\n",
        "    init_weigths = torch.ones( (n_in_f, n_out_f) )\n",
        "    init_bias = torch.zeros( (n_out_f,) )\n",
        "\n",
        "    self.l0 = nn.Linear(n_in_f, n_out_f)\n",
        "\n",
        "    const_weight = 1.\n",
        "    const_bias = 0.5\n",
        "\n",
        "    init.constant_(self.l0.weight, const_weight)\n",
        "    if self.l0.bias is not None:\n",
        "      init.constant_(self.l0.bias, const_bias)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.l0(x)\n",
        "\n",
        "class SimpleModel1(nn.Module):\n",
        "\n",
        "  def __init__(self, n_in_f, n_out_f):\n",
        "\n",
        "    super().__init__()\n",
        "\n",
        "    init_weigths = torch.ones( (n_in_f, n_out_f) )\n",
        "    init_bias = torch.zeros( (n_out_f,) )\n",
        "\n",
        "    self.l0 = nn.Linear(n_in_f, n_out_f)\n",
        "\n",
        "    const_weight = 2.\n",
        "    const_bias = 1.5\n",
        "\n",
        "    init.constant_(self.l0.weight, const_weight)\n",
        "    if self.l0.bias is not None:\n",
        "      init.constant_(self.l0.bias, const_bias)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.l0(x)\n",
        "\n",
        "\n",
        "# 모델 객체를 생성하고, 이에 대한 파라메터 확인후\n",
        "# 파라메터만 저장.\n",
        "model = SimpleModel0(3,1)\n",
        "print(list(model.named_parameters()))\n",
        "torch.save(model.state_dict(), 'model_params.pth')\n",
        "\n",
        "# 새로운 모델 객체를 생성.\n",
        "# 해당 모델 객체는 구조는 같으나, 파라메터들의 초기값은 다름.\n",
        "n_model = SimpleModel1(3,1)\n",
        "\n",
        "print('===============')\n",
        "for old, new in zip(model.parameters(), n_model.parameters()):\n",
        "\n",
        "  if not torch.equal(old,new):\n",
        "    print('model and n_model w/ default init do not have parameters with the same values!')\n",
        "    break\n",
        "else:\n",
        "  print('model and n_model w/ default init have parameters with the same values!')\n",
        "print('===============')\n",
        "\n",
        "# 이전 저장한 parameters에 대한 state_dict를\n",
        "# 로드하고 해당 state_dict로 새로만든 모델의\n",
        "# 파라메터를 설정하고 이전 모델과 비교.\n",
        "# load parameters and restore old parameters into new model\n",
        "loaded_params_ordered_dict = torch.load('model_params.pth')\n",
        "print(f'{type(loaded_params_ordered_dict)=}') # collections.OredredDict\n",
        "\n",
        "ret_v = n_model.load_state_dict(loaded_params_ordered_dict)\n",
        "print(f'{type(ret_v)}: {ret_v}')\n",
        "\n",
        "print('===============')\n",
        "for old, new in zip(model.parameters(), n_model.parameters()):\n",
        "\n",
        "  if not torch.equal(old,new):\n",
        "    print('model and n_model do not have parameters with the same values!')\n",
        "    break\n",
        "else:\n",
        "  print('model and n_model have parameters with the same values!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ult44kEoL3tH",
        "outputId": "b9115121-2a82-4e33-854f-67663355d25a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('l0.weight', Parameter containing:\n",
            "tensor([[1., 1., 1.]], requires_grad=True)), ('l0.bias', Parameter containing:\n",
            "tensor([0.5000], requires_grad=True))]\n",
            "===============\n",
            "model and n_model w/ default init do not have parameters with the same values!\n",
            "===============\n",
            "type(loaded_params_ordered_dict)=<class 'collections.OrderedDict'>\n",
            "<class 'torch.nn.modules.module._IncompatibleKeys'>: <All keys matched successfully>\n",
            "===============\n",
            "model and n_model have parameters with the same values!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "버전이 크게 바뀔 경우 안 될 확률이 매우 높음.\n",
        "주기적으로 읽어서 최신 버전으로 다시 저장 필요."
      ],
      "metadata": {
        "id": "jdB1ZNJJTjg0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensor 비교"
      ],
      "metadata": {
        "id": "JRGm2rkbUWg_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch에서 nn.Parameter 또는 tensor 객체 두 개가 같은 값을 가지는지 확인하는 방법은 텐서의 모든 요소가 동일한지 확인하는 것임.\n",
        "\n",
        "\n",
        "\n",
        "이를 위해 제공되는 다음과 같은 함수 2개가 존재함.\n",
        "\n",
        "torch.equal : 두 텐서의 모든 요소가 동일한지 확인\n",
        "torch.allclose : 지정된 허용 오차 내에서 두 텐서가 거의 동일한지 확인."
      ],
      "metadata": {
        "id": "RsiTGQ_cUwa1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `torch.equal` 사용\n",
        "https://ds31x.tistory.com/265"
      ],
      "metadata": {
        "id": "9v6CjNM5VRNg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# nn.Parameter 객체 생성\n",
        "param1 = nn.Parameter(torch.tensor([1.0, 2.0, 3.0]))\n",
        "param2 = nn.Parameter(torch.tensor([1.0, 2.0, 3.0]))\n",
        "param3 = nn.Parameter(torch.tensor([1.0, 2.0, 4.0]))\n",
        "\n",
        "# 값 비교\n",
        "print(torch.equal(param1, param2))  # True\n",
        "print(torch.equal(param1, param3))  # False"
      ],
      "metadata": {
        "id": "2t8Iu9vTVWlM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `torch.allclose` 사용\n",
        "이 방법은 두 텐서가 지정된 허용 오차 내에서 거의 동일한지를 확인.\n",
        "\n",
        "이는 부동 소수점 연산의 미세한 차이로 인한 불일치를 허용할 수 있음 (권장)."
      ],
      "metadata": {
        "id": "es8eLtyyVXRJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://ds31x.tistory.com/266"
      ],
      "metadata": {
        "id": "A6lyfzuXWRdb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이름을 지정하면 디버깅시 확인이 매우 편함."
      ],
      "metadata": {
        "id": "dYUaG2anXmG0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "일반 list / dict를 사용하면 선언이 되지 않고 parameter로 선언이 안 되기 때문에 하습 자체가 불가."
      ],
      "metadata": {
        "id": "5ppBIvouZVfm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "loss가 기존보다 줄었다면 모델 저장 기능 추가. -> checkpoint.\n",
        "epoch마다 저장하는 것은 파일명에 에포크수가 포함되어 있어야 함.\n",
        "+날짜 및 시간"
      ],
      "metadata": {
        "id": "0QherU59a4Ir"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "optimizer의 상태도 그대로 저장해야 함."
      ],
      "metadata": {
        "id": "sjbHPBKYbvxJ"
      }
    }
  ]
}