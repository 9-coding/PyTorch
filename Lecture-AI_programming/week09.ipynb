{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOy78lNuoA+824OKlBEwKk/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/9-coding/PyTorch/blob/main/Lecture-AI_programming/week09.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Week09\n",
        "## 모델 저장하기"
      ],
      "metadata": {
        "id": "XNdqc3lr7vzj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import init\n",
        "from collections import OrderedDict"
      ],
      "metadata": {
        "id": "pcfTQO7WyURv"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `state_dict()`\n",
        "`torch.nn.Module` 객체의 `state_dict()` 메서드.\n",
        "\n",
        "- 모델의 학습 가능한 parameters의 상태와\n",
        "- 버퍼(예: BatchNorm의 running mean과 variance 등)의 상태를 저장하는\n",
        "- collections.OrderedDict 객체를 반환.\n",
        "- 반환된 객체는 모델의 현재 상태를 나타내며, 저장 및 로드가 가능."
      ],
      "metadata": {
        "id": "XBeRoZTO7vhe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. OrderedDict 형태:\n",
        "- attribute 이름을 키로 하고,\n",
        "- 그에 대응하는 torch.Tensor를 값으로 갖는\n",
        "- `collections.OrderedDict` 객체를 반환.\n",
        "2. 학습 가능한 매개변수:\n",
        "- `torch.nn.Parameter` 객체로 정의된 모든 학습 가능한 attributes를 포함.\n",
        "3. 버퍼:\n",
        "- 모델에 포함된 모든 버퍼(예: BatchNorm 계층의 running mean과 variance)도 포함."
      ],
      "metadata": {
        "id": "AcazBMfv-aWP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Serialization: 개체를 key: value 형태로 하여 직렬화로 저장.\n",
        "- OrderedDict: 순서가 정의된 딕셔너리 형태.\n",
        "\n"
      ],
      "metadata": {
        "id": "z0njj61E8RPW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## parameters\n",
        "`state_dict(desitnation=None, prefix='', keep_vars=False)`\n",
        "### keep_vars\n",
        "buffers와 parameters의 값만을 추출할지 결정\n",
        "- 저장의 용도로는 keep_vars=False를 사용하는 게 좋음.\n",
        "\n",
        "**keep_vars=True인 경우**\n",
        "- value가 parameter인 경우엔 Parameter 로 얻어짐.\n",
        "- value가 buffer인 경우엔 Tensor 로 얻어짐.\n",
        "- 메모리 사용량이 커지고, 매우 느리고 복잡한 동작 발생.\n",
        "\n",
        "**장점**\n",
        "- 모델 디버깅: 모델 상태를 조사하고 특정 매개 변수나 버퍼의 값을 변경해야 하는 경우 유용\n",
        "- 모델 커스터마이징: 모델을 불러온 후 특정 매개 변수나 버퍼의 값을 변경해야 하는 경우 유용\n",
        "- 모델 저장 및 불러오기 확장: 모델 저장 및 불러오기 프로세스를 확장하고 추가적인 정보를 저장해야 하는 경우 유용\n",
        "\n"
      ],
      "metadata": {
        "id": "wTj2Ev9SF9D4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 간단한 모델 정의\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.linear = nn.Linear(10, 5)\n",
        "        self.bn = nn.BatchNorm1d(5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        x = self.bn(x)\n",
        "        return x\n",
        "\n",
        "# 모델 인스턴스 생성\n",
        "model = MyModel()\n",
        "\n",
        "# 모델의 state_dict 가져오기\n",
        "state_dict = model.state_dict()\n",
        "\n",
        "# state_dict 내용 출력\n",
        "for key, value in state_dict.items():\n",
        "    print(f\"{key}: {value.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9MhjrFL_4B4",
        "outputId": "6d1a8243-9f63-4d25-fdfa-9fc1e653d610"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "linear.weight: torch.Size([5, 10])\n",
            "linear.bias: torch.Size([5])\n",
            "bn.weight: torch.Size([5])\n",
            "bn.bias: torch.Size([5])\n",
            "bn.running_mean: torch.Size([5])\n",
            "bn.running_var: torch.Size([5])\n",
            "bn.num_batches_tracked: torch.Size([])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `linear`: `nn.Linear`\n",
        "- `linear.weight`: weight parameter\n",
        "- `linear.bias`: bias parameter\n",
        "\n",
        "### `bn`: `nn.BatchNorm1d`\n",
        "- `bn.weight`: weight parameter\n",
        "- `bn.bias`: bias parameter\n",
        "- `bn.running_mean`: running mean buffer\n",
        "- `bn.running_var`: running variance buffer\n",
        "- `bn.num_batches_tracked`: 배치의 수 추적 buffer"
      ],
      "metadata": {
        "id": "K0ICc1U1T3XW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델의 state_dict 가져오기\n",
        "state_dict0 = model.state_dict(prefix='ds', keep_vars=True)\n",
        "\n",
        "# state_dict 내용 출력\n",
        "for key, value in state_dict0.items():\n",
        "    print(f\"{key}: {value.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hwrwk23VE4m1",
        "outputId": "44a8820b-de62-4f8c-d70e-61c7199981c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dslinear.weight: torch.Size([5, 10])\n",
            "dslinear.bias: torch.Size([5])\n",
            "dsbn.weight: torch.Size([5])\n",
            "dsbn.bias: torch.Size([5])\n",
            "dsbn.running_mean: torch.Size([5])\n",
            "dsbn.running_var: torch.Size([5])\n",
            "dsbn.num_batches_tracked: torch.Size([])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 저장\n",
        "\n",
        "state_dict를 파일에 저장하여 나중에 모델을 복원할 수 있음."
      ],
      "metadata": {
        "id": "AIXuEganHnjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'model_state.pth')"
      ],
      "metadata": {
        "id": "HmO9XptYHlE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 로드\n",
        "\n",
        "저장된 state_dict를 로드하여 모델을 복원."
      ],
      "metadata": {
        "id": "8jGxMXR8HsXj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyModel()\n",
        "model.load_state_dict(torch.load('model_state.pth'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHmK38jSHt5Z",
        "outputId": "3d9e0635-f063-47b4-88bc-b97677346fbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 파라미터 업데이트\n",
        "\n",
        "state_dict를 사용하여 모델의 특정 파라미터를 업데이트할 수 있음."
      ],
      "metadata": {
        "id": "xfzWfOZeHvPW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "state_dict['linear.weight'] = torch.ones_like(state_dict['linear.weight'])\n",
        "model.load_state_dict(state_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cw6mX_fEHxI5",
        "outputId": "ea35de94-2f5e-440c-edc3-343c9c67d10c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr>"
      ],
      "metadata": {
        "id": "xto6bpx1YIcb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save and Load Model"
      ],
      "metadata": {
        "id": "cKhuWei58CXt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 모델의 Parameters 저장\n",
        "- Structure 등은 저장되지 않음.\n",
        "- PyTorch 버전에 관계없이 사용 가능."
      ],
      "metadata": {
        "id": "FqQj2A4boHD2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `state_dict()`\n",
        "- 객체의 상태를 가지고 있어 상태를 저장하고 복원할 수 있음.\n",
        "- 모델의 parameter 상태와 buffer의 상태 저장\n",
        "- 현재 Module instance의 상태에 해당하는 OrderedDict 객체 `state_dict` 반환.\n"
      ],
      "metadata": {
        "id": "a9nkpCwjoFLo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `load_state_dict(state_dict)`\n",
        "현재 Module 인스턴스의 상태를 argument로 넘겨진 OrderedDict 객체 state_dict를 이용해 설정\n",
        "\n",
        "- missing_keys : 로드하려는 state_dict에는 있으나 load_state_dict메서드를 호출한 Module 객체에는 없는 키들.\n",
        "- unexpected_keys : Module 객체에는 있으나 인자로 넘겨진 state_dict에는 없는 키들."
      ],
      "metadata": {
        "id": "kFevbUSJsiYs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `torch.save(state_dict,'file_path') & state_dict=torch.load('file_path')`\n",
        "\n",
        "`state_dict`객체는 torch의 `save` `load`를 이용해 파일로 저장되거나 로딩됨."
      ],
      "metadata": {
        "id": "JlklNPYPuUbS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self, n_in_f, n_out_f, w, b):\n",
        "    super().__init__()\n",
        "    init_weigths = torch.ones( (n_in_f, n_out_f) )\n",
        "    init_bias = torch.zeros( (n_out_f,) )\n",
        "\n",
        "    self.l0 = nn.Linear(n_in_f, n_out_f)\n",
        "\n",
        "    init.constant_(self.l0.weight, w)\n",
        "    if self.l0.bias is not None:\n",
        "      init.constant_(self.l0.bias, b)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.l0(x)"
      ],
      "metadata": {
        "id": "1Tpv8WqDyb9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 객체를 생성하고, 이에 대한 파라메터 확인후\n",
        "# 파라메터만 저장.\n",
        "model1 = Model(3, 1, 1., 0.5)\n",
        "print(list(model1.named_parameters()))\n",
        "torch.save(model1.state_dict(), 'model_params.pth')\n",
        "\n",
        "# 새로운 모델 객체를 생성.\n",
        "# 해당 모델 객체는 구조는 같으나, 파라메터들의 초기값은 다름.\n",
        "model2 = Model(3, 1, 2., 1.5)\n",
        "\n",
        "print('===============')\n",
        "for old, new in zip(model1.parameters(), model2.parameters()):\n",
        "\n",
        "  if not torch.equal(old,new):\n",
        "    print('model and n_model w/ default init do not have parameters with the same values!')\n",
        "    break\n",
        "else:\n",
        "  print('model and n_model w/ default init have parameters with the same values!')\n",
        "print('===============')\n",
        "\n",
        "# 이전 저장한 parameters에 대한 state_dict를\n",
        "# 로드하고 해당 state_dict로 새로만든 모델의\n",
        "# 파라메터를 설정하고 이전 모델과 비교.\n",
        "# load parameters and restore old parameters into new model\n",
        "loaded_params_ordered_dict = torch.load('model_params.pth')\n",
        "print(f'{type(loaded_params_ordered_dict)=}') # collections.OredredDict\n",
        "\n",
        "ret_v = model2.load_state_dict(loaded_params_ordered_dict)\n",
        "print(f'{type(ret_v)}: {ret_v}')\n",
        "\n",
        "print('===============')\n",
        "for old, new in zip(model1.parameters(), model2.parameters()):\n",
        "\n",
        "  if not torch.equal(old,new):\n",
        "    print('model and n_model do not have parameters with the same values!')\n",
        "    break\n",
        "else:\n",
        "  print('model and n_model have parameters with the same values!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ult44kEoL3tH",
        "outputId": "53d0805b-840d-4cfa-8c38-904b7e17d3d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('l0.weight', Parameter containing:\n",
            "tensor([[1., 1., 1.]], requires_grad=True)), ('l0.bias', Parameter containing:\n",
            "tensor([0.5000], requires_grad=True))]\n",
            "===============\n",
            "model and n_model w/ default init do not have parameters with the same values!\n",
            "===============\n",
            "type(loaded_params_ordered_dict)=<class 'collections.OrderedDict'>\n",
            "<class 'torch.nn.modules.module._IncompatibleKeys'>: <All keys matched successfully>\n",
            "===============\n",
            "model and n_model have parameters with the same values!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## model 전체 저장\n",
        "- Parameters와 Structure 함께 저장\n",
        "- pickle에 의존하여 인스턴스를 직렬화하므로 모델 클래스 정의가 필요함.\n",
        "- 버전이 크게 바뀔 경우 안 될 확률이 매우 높으므로 주기적으로 최신 버전으로 다시 저장 필요."
      ],
      "metadata": {
        "id": "HI3gpstTnPcU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 저장할 모델 생성.\n",
        "model = Model(3, 1, 2., 1.5)\n",
        "\n",
        "# 모델 저장\n",
        "torch.save(model, 'model.pth')\n",
        "\n",
        "# 저장된 model 로드.\n",
        "n_model = torch.load('model.pth')\n",
        "print(f'{type(n_model)=}, {n_model}')\n",
        "\n",
        "# 두 모델의 parameters비교.\n",
        "for old, new in zip(model.parameters(), n_model.parameters()):\n",
        "  if not torch.equal(old,new):\n",
        "    print('model and n_model do not have parameters with the same values!')\n",
        "    break\n",
        "else:\n",
        "  print('model and n_model have parameters with the same values!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jUY-nTIu7ty",
        "outputId": "c394444f-b7ed-4221-fe25-1022a405089a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "type(n_model)=<class '__main__.Model'>, Model(\n",
            "  (l0): Linear(in_features=3, out_features=1, bias=True)\n",
            ")\n",
            "model and n_model have parameters with the same values!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr>"
      ],
      "metadata": {
        "id": "pyQMRD6q8NzF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensor 비교"
      ],
      "metadata": {
        "id": "JRGm2rkbUWg_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch에서 `nn.Parameter` 또는 `tensor` 객체 두 개가 같은 값을 가지는지 확인하는 방법.\n",
        "- `torch.equal` : 두 텐서의 모든 요소가 동일한지 확인\n",
        "- `torch.allclose` : 지정된 허용 오차 내에서 두 텐서가 거의 동일한지 확인."
      ],
      "metadata": {
        "id": "RsiTGQ_cUwa1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `torch.equal` 사용\n",
        "- 완벽히 같은 값을 가질 때만 `True` 반환."
      ],
      "metadata": {
        "id": "9v6CjNM5VRNg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# nn.Parameter 객체 생성\n",
        "param1 = nn.Parameter(torch.tensor([1.0, 2.0, 3.0]))\n",
        "param2 = nn.Parameter(torch.tensor([1.0, 2.0, 3.0]))\n",
        "param3 = nn.Parameter(torch.tensor([1.0, 2.0, 4.0]))\n",
        "\n",
        "# 값 비교\n",
        "print(torch.equal(param1, param2))  # True\n",
        "print(torch.equal(param1, param3))  # False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2t8Iu9vTVWlM",
        "outputId": "21872842-e84b-4d32-b344-9f6c9e3cda4a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `torch.allclose` 사용\n",
        "- 두 텐서가 지정된 허용 오차 내에서 거의 동일한지 확인.\n",
        "- 부동 소수점 연산의 미세한 차이로 인한 불일치를 허용할 수 있음"
      ],
      "metadata": {
        "id": "es8eLtyyVXRJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param2 = nn.Parameter(torch.tensor([1.0, 2.00001, 3.0]))\n",
        "\n",
        "# 값 비교\n",
        "print(torch.allclose(param1, param2))  # True, 기본 허용 오차 내\n",
        "print(torch.allclose(param1, param3))  # False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QtfPWkSyby8",
        "outputId": "1ba96363-ab9b-4117-dcb1-163b77d980c5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 허용 오차 설정\n",
        "`torch.allclose(tensor1, tensor2, rtol=1e-05, atol=1e-08)`\n",
        "- 절대적(atol), 상대적(rtol) 허용 오차 설정 가능."
      ],
      "metadata": {
        "id": "c5JSKfNUys44"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param2 = nn.Parameter(torch.tensor([1.0, 2.0, 3.0001]))\n",
        "\n",
        "print(torch.allclose(param1, param2, atol=1e-4))  # True, 허용 오차 내\n",
        "print(torch.allclose(param1, param2, atol=1e-5))  # False, 허용 오차 밖"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_x7oMevzC6F",
        "outputId": "36e7cad0-3cef-49ba-e2b6-0bda8c87452a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 절대적 오차 (`atol`)\n",
        "$\\mathrm{atol} = |a-b|$\n",
        "- 두 값의 차이가 일정한 허용 오차인지 확인.\n",
        "- 값 크기에 상관없이 일정\n",
        "\n",
        "$ a = 100$이고 $b = 100.1$이면\n",
        "\n",
        "$\\mathrm{atol} = |100-100.1| = 0.1$\n"
      ],
      "metadata": {
        "id": "udxtWH8qzkrl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 상대적 오차 (`rtol`)\n",
        "$\\mathrm{rtol} = \\cfrac{|a-b|}{|b|}$\n",
        "- 두 값의 차이가 값에 크기에 비례한 허용 오차인지 확인.\n",
        "- 값 크기에 비례함.\n",
        "\n",
        "$ a = 100$이고 $b = 100.1$이면\n",
        "\n",
        "$\\mathrm{rtol} = \\cfrac{|100-100.1|}{|100.1|} \\approx 0.001$\n"
      ],
      "metadata": {
        "id": "JK4nCMHv2N9D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `torch.allclose`의 유사 기준\n",
        "$|a_i - b_i| \\leq \\mathrm{atol}+|b_i| \\times \\mathrm{rtol}$"
      ],
      "metadata": {
        "id": "Vs9s51wZ2-Rb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr>"
      ],
      "metadata": {
        "id": "2TJIMhOX3pfh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `nn.Sequential`"
      ],
      "metadata": {
        "id": "CTuQLpat3vyJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `nn.ModuleList`"
      ],
      "metadata": {
        "id": "xbGHUmIx36CK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `nn.ModulDict`"
      ],
      "metadata": {
        "id": "EkQMP2J63_QQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://ds31x.tistory.com/266"
      ],
      "metadata": {
        "id": "A6lyfzuXWRdb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이름을 지정하면 디버깅시 확인이 매우 편함."
      ],
      "metadata": {
        "id": "dYUaG2anXmG0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "일반 list / dict를 사용하면 선언이 되지 않고 parameter로 선언이 안 되기 때문에 하습 자체가 불가."
      ],
      "metadata": {
        "id": "5ppBIvouZVfm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "loss가 기존보다 줄었다면 모델 저장 기능 추가. -> checkpoint.\n",
        "epoch마다 저장하는 것은 파일명에 에포크수가 포함되어 있어야 함.\n",
        "+날짜 및 시간"
      ],
      "metadata": {
        "id": "0QherU59a4Ir"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "optimizer의 상태도 그대로 저장해야 함."
      ],
      "metadata": {
        "id": "sjbHPBKYbvxJ"
      }
    }
  ]
}